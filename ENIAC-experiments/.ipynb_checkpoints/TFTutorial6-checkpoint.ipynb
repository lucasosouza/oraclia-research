{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([[1,0.7,0.2],[.9, .1, .3], [.1, .3, .2], [0, .1, .5]])\n",
    "y_train = np.array([1,1,0,0])\n",
    "n = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"input\"):\n",
    "    # define variables\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n], name='x')\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 1], name='y')\n",
    "\n",
    "with tf.name_scope(\"regression\"):\n",
    "    # define variables\n",
    "    W = tf.Variable(tf.zeros([n,1], dtype=tf.float32), name='weights')\n",
    "    b = tf.Variable(tf.zeros([1], dtype=tf.float32), name='biases')\n",
    "    \n",
    "with tf.name_scope(\"operations\"):\n",
    "    # regular calculation of pred, similar to linear regression\n",
    "    st1 = tf.add(tf.matmul(X ,W), b)\n",
    "    \n",
    "    # sigmoid converts from 0 to 1\n",
    "    y_pred = tf.nn.sigmoid(st1)\n",
    "        \n",
    "    # compute regular error functions\n",
    "    squared_error = tf.square(tf.subtract(y_pred, y))\n",
    "    loss = tf.reduce_sum(squared_error)\n",
    "    \n",
    "    # result, needs to be 0 or 1\n",
    "    res = tf.round(y_pred)\n",
    "    \n",
    "    # define optimization\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "# creat a summary for x and y\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "# no need to specify graph\n",
    "writer = tf.summary.FileWriter('./example', graph=tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63082564]\n",
      " [ 0.60021269]\n",
      " [ 0.49528903]\n",
      " [ 0.46885273]]\n",
      "[[ 0.64657569]\n",
      " [ 0.61155403]\n",
      " [ 0.48756066]\n",
      " [ 0.45606738]]\n",
      "[[ 0.65486765]\n",
      " [ 0.61746842]\n",
      " [ 0.48262715]\n",
      " [ 0.44827166]]\n",
      "[[ 0.66039175]\n",
      " [ 0.62139112]\n",
      " [ 0.47900173]\n",
      " [ 0.44266668]]\n",
      "[[ 0.66449094]\n",
      " [ 0.6242947 ]\n",
      " [ 0.47613677]\n",
      " [ 0.43829754]]\n",
      "[[ 0.66772884]\n",
      " [ 0.62658471]\n",
      " [ 0.47376955]\n",
      " [ 0.43472227]]\n",
      "[[ 0.67039305]\n",
      " [ 0.62846732]\n",
      " [ 0.47175363]\n",
      " [ 0.43170005]]\n",
      "[[ 0.67264938]\n",
      " [ 0.63006079]\n",
      " [ 0.46999902]\n",
      " [ 0.4290849 ]]\n",
      "[[ 0.67460185]\n",
      " [ 0.63143915]\n",
      " [ 0.46844617]\n",
      " [ 0.42678183]]\n"
     ]
    }
   ],
   "source": [
    "# run it\n",
    "epochs=100\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for epoch in range(1, epochs):\n",
    "    # loss, summary  = sess.run([train_op, summary_op], feed_dict)\n",
    "    feed_dict = {\n",
    "        X: X_train,\n",
    "        y: y_train.reshape(-1,1),\n",
    "        learning_rate: .5/epoch\n",
    "    }\n",
    "    # run\n",
    "    _, summary = sess.run([train_op, summary_op], feed_dict)\n",
    "\n",
    "    # log results\n",
    "    writer.add_summary(summary)\n",
    "    \n",
    "    # log to console\n",
    "    if epoch%(epochs/10) == 0:\n",
    "        curr_loss, curr_W, curr_b, pred = sess.run([loss, W, b, y_pred], feed_dict)\n",
    "        print(pred)\n",
    "        #print(pred)\n",
    "        # print(\"Epoch: {}, R2: {:.2f}, loss: {:.2f} \".format(epoch, r2, curr_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 1.00, loss: 0.64 \n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    X: X_train,\n",
    "    y: y_train.reshape(-1,1)\n",
    "}\n",
    "curr_loss, pred = sess.run([loss, res], feed_dict)\n",
    "acc = accuracy_score(y_train, pred)\n",
    "print(\"Acc: {:.2f}, loss: {:.2f} \".format(acc, curr_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# In scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 1.00\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_train)\n",
    "acc = accuracy_score(y_train, pred)\n",
    "print(\"Acc: {:.2f}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.73103453,  0.35862072, -0.17931036]]), array([-0.94620691]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:udacity]",
   "language": "python",
   "name": "conda-env-udacity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
