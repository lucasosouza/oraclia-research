{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 4), (112, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_iris()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "target = lb.fit_transform(target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data, target, test_size=.25, random_state=13)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = X_train.shape[1]\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46113643, -2.02367187,  0.45434329,  0.45153624], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X_train.shape[1]\n",
    "n_labels = y_train.shape[1]\n",
    "n_features, n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"input\"):\n",
    "    # define variables\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_features], name='x')\n",
    "    y = tf.placeholder(tf.float32, shape=[None, n_labels], name='y')\n",
    "\n",
    "with tf.name_scope(\"regression\"):\n",
    "    # define variables\n",
    "    W = tf.Variable(tf.truncated_normal([n_features,n_labels], dtype=tf.float32, stddev=.01), name='weights')\n",
    "    b = tf.Variable(tf.zeros([n_labels], dtype=tf.float32), name='biases')\n",
    "    \n",
    "with tf.name_scope(\"operations\"):\n",
    "    # regular calculation of pred, similar to linear regression\n",
    "    logits = tf.add(tf.matmul(X ,W), b)\n",
    "    \n",
    "    # softmax will convert to a probability distribution\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "        \n",
    "    # compute regular error functions\n",
    "    # cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "    # loss = tf.losses.log_loss(softmax, y)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "    # result, needs to be 0 or 1\n",
    "    # correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(softmax,1))\n",
    "    # y_pred = tf.argmax(softmax, 1)\n",
    "    \n",
    "    # define optimization\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "# creat a summary for x and y\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "# no need to specify graph\n",
    "writer = tf.summary.FileWriter('./example', graph=tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.96, loss: 0.19 \n",
      "Acc: 0.96, loss: 0.14 \n",
      "Acc: 0.98, loss: 0.11 \n",
      "Acc: 0.98, loss: 0.10 \n",
      "Acc: 0.98, loss: 0.09 \n",
      "Acc: 0.98, loss: 0.08 \n",
      "Acc: 0.98, loss: 0.07 \n",
      "Acc: 0.98, loss: 0.07 \n",
      "Acc: 0.98, loss: 0.07 \n"
     ]
    }
   ],
   "source": [
    "# run it\n",
    "epochs=20000\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "losses = []\n",
    "for epoch in range(1, epochs):\n",
    "    # loss, summary  = sess.run([train_op, summary_op], feed_dict)\n",
    "    feed_dict = {\n",
    "        X: X_train_scaled,\n",
    "        y: y_train,\n",
    "        learning_rate: .02\n",
    "    }\n",
    "    # run\n",
    "    _, summary, loss_ = sess.run([train_op, summary_op, loss], feed_dict)\n",
    "\n",
    "    losses.append(loss_)\n",
    "    \n",
    "    # log results\n",
    "    writer.add_summary(summary)\n",
    "    \n",
    "    # log to console\n",
    "    if epoch%(epochs/10) == 0:\n",
    "        curr_loss, curr_W, curr_b, pred = sess.run([loss, W, b, softmax], feed_dict)\n",
    "        # print(curr_loss)\n",
    "        acc = accuracy_score(np.argmax(y_train, 1), np.argmax(pred, 1))\n",
    "        print(\"Acc: {:.2f}, loss: {:.2f} \".format(acc, curr_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0,\n",
       "        0, 2, 1, 2, 2, 0, 2, 1, 1, 0, 0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 2, 0, 2,\n",
       "        1, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 2, 0, 2, 1, 0, 2, 0, 0, 0, 1, 0, 1,\n",
       "        1, 2, 2, 0, 2, 0, 1, 1, 2, 0, 2, 0, 1, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 2, 1, 0, 1, 1]),\n",
       " array([1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 0, 1, 2, 2, 0,\n",
       "        0, 2, 1, 2, 2, 0, 2, 1, 1, 0, 0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 2, 0, 2,\n",
       "        1, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 2, 0, 2, 1, 0, 2, 0, 0, 0, 1, 0, 1,\n",
       "        1, 2, 2, 0, 1, 0, 1, 1, 2, 0, 2, 0, 1, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 2, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred, 1), np.argmax(y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.85281742,  1.35762477,  0.4971602 ],\n",
       "        [ 1.71766376, -0.45415202, -1.2657181 ],\n",
       "        [-3.12245345, -0.97211236,  4.0975709 ],\n",
       "        [-2.97668934, -1.01792395,  4.00237417]], dtype=float32),\n",
       " array([-0.39082167,  3.61333537, -3.22252488], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_W, curr_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  5.85038151e-06,   7.34984934e-01,   2.65009165e-01],\n",
       "        [  9.94616210e-01,   5.38385287e-03,   1.94919619e-11],\n",
       "        [  9.97449815e-01,   2.55013467e-03,   5.94321120e-12],\n",
       "        [  1.01948153e-05,   3.11950892e-01,   6.88038945e-01],\n",
       "        [  5.10007283e-03,   9.78581131e-01,   1.63187236e-02],\n",
       "        [  2.39182896e-07,   9.06806588e-02,   9.09319103e-01],\n",
       "        [  9.80332970e-06,   1.47161067e-01,   8.52829099e-01],\n",
       "        [  4.87663776e-09,   1.55191869e-03,   9.98448014e-01],\n",
       "        [  9.97036219e-01,   2.96377414e-03,   9.31677478e-12],\n",
       "        [  1.97491180e-02,   9.79146302e-01,   1.10456068e-03]], dtype=float32),\n",
       " array([[0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(pred.astype(np.int32).reshape(-1))\n",
    "pred[:10], y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9821, loss: 0.07 \n",
      "Acc: 0.9737, loss: 0.09 \n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    X: scaler.transform(X_train),\n",
    "    y: y_train\n",
    "}\n",
    "\n",
    "curr_loss, pred = sess.run([loss, softmax], feed_dict)\n",
    "acc = accuracy_score(np.argmax(y_train, 1), np.argmax(pred, 1))\n",
    "print(\"Acc: {:.4f}, loss: {:.2f} \".format(acc, curr_loss))\n",
    "\n",
    "feed_dict = {\n",
    "    X: scaler.transform(X_test),\n",
    "    y: y_test\n",
    "}\n",
    "curr_loss, pred = sess.run([loss, softmax], feed_dict)\n",
    "acc = accuracy_score(np.argmax(y_test, 1), np.argmax(pred, 1))\n",
    "print(\"Acc: {:.4f}, loss: {:.2f} \".format(acc, curr_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# In scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 4), (112,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_iris()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data, target, test_size=.25, random_state=13)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9821\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_train)\n",
    "acc = accuracy_score(y_train, pred)\n",
    "print(\"Acc: {:.4f}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 0, 1, 2, 2, 0,\n",
       "        0, 2, 1, 2, 2, 0, 2, 1, 1, 0, 0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 2, 0, 2,\n",
       "        1, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 2, 0, 2, 1, 0, 2, 0, 0, 0, 1, 0, 1,\n",
       "        1, 2, 2, 0, 1, 0, 1, 1, 2, 0, 2, 0, 1, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 2, 1, 0, 1, 1]),\n",
       " array([1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0,\n",
       "        0, 2, 1, 2, 2, 0, 2, 1, 1, 0, 0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 2, 0, 2,\n",
       "        1, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 2, 0, 2, 1, 0, 2, 0, 0, 0, 1, 0, 1,\n",
       "        1, 2, 2, 0, 2, 0, 1, 1, 2, 0, 2, 0, 1, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 2, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(\"Acc: {:.4f}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.2,  2.2,  4.5,  1.5]),\n",
       " array([[-0.25163786,  0.47811307, -0.85347203, -0.61651333],\n",
       "        [-0.02034588,  0.18311289, -0.52899281, -0.30518816],\n",
       "        [ 0.78613759,  0.46053208, -2.02000442, -1.50339089]]),\n",
       " array([ 2.32700222,  1.54120035,  6.21300813]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(-1.8528174, -0.25163786049925418),\n",
       "  (1.7176638, 0.4781130713458126),\n",
       "  (-3.1224535, -0.8534720276259451),\n",
       "  (-2.9766893, -0.61651332642178791)],\n",
       " [(-0.39082167, 2.3270022150828358),\n",
       "  (3.6133354, 1.5412003479828156),\n",
       "  (-3.2225249, 6.2130081288127048)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(curr_W[:, 0], clf.coef_[0, :])), list(zip(curr_b, clf.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:udacity]",
   "language": "python",
   "name": "conda-env-udacity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
